{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Nessecary Libraries\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchinfo import summary     #not used now but will use in future\n",
    "from going_modular import data_setup, engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__, torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# Batch_size of dataset\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds\n",
    "def set_seeds(seed: int=42):\n",
    "    \n",
    "    # Set the seed for general torch operations\n",
    "    torch.manual_seed(seed)\n",
    "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "image_path = Path(r'D:/GinnyPig/Wildfire/validation_dataset')\n",
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup directories\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path /\"test\"\n",
    "valid_dir = image_path /'valid'\n",
    "\n",
    "train_dir, test_dir, valid_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT \n",
    "\n",
    "# Get transforms from weights (these are the transforms used to train a particular or obtain a particular set of weights)\n",
    "automatic_transforms = weights.transforms()\n",
    "print(f\"Automatically created transforms: {automatic_transforms}\")\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
    "                                                                               test_dir=test_dir,\n",
    "                                                                               transform=automatic_transforms,\n",
    "                                                                               batch_size=batch_size)\n",
    "train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the pretrained weights for EfficientNet_B0\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT \n",
    "\n",
    "# Setup the model with the pretrained weights and send it to the target device\n",
    "model = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the classifier head\n",
    "from torch import nn\n",
    "\n",
    "set_seeds()\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1280, out_features=len(class_names))).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model,\n",
    "        input_size=(32, 3, 224, 224),\n",
    "        verbose=0,\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training starts from here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a SummaryWriter\n",
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from going_modular.engine import train_step, test_step\n",
    "\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device) -> Dict[str, List]:\n",
    "    \n",
    "    # Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"test_loss\": [],\n",
    "               \"test_acc\": []\n",
    "    }\n",
    "\n",
    "    # Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                          dataloader=train_dataloader,\n",
    "                                          loss_fn=loss_fn,\n",
    "                                          optimizer=optimizer,\n",
    "                                          device=device)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "          dataloader=test_dataloader,\n",
    "          loss_fn=loss_fn,\n",
    "          device=device)\n",
    "\n",
    "        # Print out what's happening\n",
    "        print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "        ### New: Experiment tracking ###\n",
    "        # See SummaryWriter documentation\n",
    "        writer.add_scalars(main_tag=\"Loss\",\n",
    "                           tag_scalar_dict={\"train_loss\": train_loss,\n",
    "                                            \"test_loss\": test_loss},\n",
    "                           global_step=epoch)\n",
    "        \n",
    "        writer.add_scalars(main_tag=\"Accuracy\",\n",
    "                           tag_scalar_dict={\"train_acc\": train_acc,\n",
    "                                            \"test_acc\": test_acc},\n",
    "                           global_step=epoch)\n",
    "        \n",
    "        writer.add_graph(model=model,\n",
    "                         input_to_model=torch.randn(32, 3, 224, 224).to(device))\n",
    "\n",
    "    # Close the writer\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "    # Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds()\n",
    "results = train(model=model,\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                optimizer=optimizer,\n",
    "                loss_fn=loss_fn,\n",
    "                epochs=2,\n",
    "                device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "\n",
    "from going_modular.utils import save_model\n",
    "\n",
    "save_model(model=model,\n",
    "           target_dir=r\"model\",\n",
    "           model_name=r\"EfficientNet_b0-Wildfire_Classifier.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from going_modular.utils import load_model\n",
    "from pathlib import Path\n",
    "from going_modular import data_setup, engine\n",
    "\n",
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# Batch_size of dataset\n",
    "batch_size = 32\n",
    "\n",
    "from pathlib import Path\n",
    "image_path = Path(r'C:/GinnyPig/Wildfire/validation_dataset')\n",
    "image_path\n",
    "\n",
    "valid_dir = image_path /'valid'\n",
    "\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # \"DEFAULT\" = best available\n",
    "\n",
    "# Get transforms from weights (these are the transforms used to train a particular or obtain a particular set of weights)\n",
    "automatic_transforms = weights.transforms()\n",
    "\n",
    "# Loss function for prediciton\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "model_loaded = torchvision.models.efficientnet_b0().to(device)\n",
    "\n",
    "model_loaded.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1280, out_features=2)).to(device) \n",
    "\n",
    "model_loaded = load_model(model_loaded, Path(r\"model\\EfficientNet_b0-Wildfire_Classifier.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Validation Dataset\n",
    "\n",
    "valid_dataset = torchvision.datasets.ImageFolder(root=valid_dir,\n",
    "                                                 transform=automatic_transforms,\n",
    "                                                 is_valid_file=data_setup.check_Image)\n",
    "\n",
    "valid_dataloader = torch.utils.data.DataLoader(\n",
    "      valid_dataset,\n",
    "      batch_size=batch_size,\n",
    "      shuffle=False,\n",
    "      pin_memory=True,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the validation dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "model_loaded.eval()\n",
    "\n",
    "valid_loss = 0\n",
    "valid_acc = 0\n",
    "\n",
    "for X, y in tqdm(valid_dataloader):\n",
    "    # Copy to device\n",
    "    X , y = X.to(device), y.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    y_logits = model_loaded(X)\n",
    "\n",
    "    # 2. Calculate and accumulate loss\n",
    "    loss = loss_fn(y_logits, y)\n",
    "    valid_loss += loss.item()\n",
    "\n",
    "    # Calculate and accumulate accuracy\n",
    "    test_pred_labels = y_logits.argmax(dim=1)\n",
    "    valid_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "\n",
    "# Adjust metrics to get average loss and accuracy per batch \n",
    "valid_loss = valid_loss / len(valid_dataloader)\n",
    "valid_acc = valid_acc / len(valid_dataloader)\n",
    "\n",
    "print(f'Validation Loss- {valid_loss}')\n",
    "print(f'Validation Acc - {valid_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "not_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
